@string{journal_tvcg = {IEEE Transactions on Visualization and Computer Graphics}}
@string{journal_jov = {Journal of Visualization}}
@string{conf_chi = {Proc. ACM Conf. Human Factors in Computing Systems (CHI)}}
@string{conf_chi = {Proc. ACM Conf. Human Factors in Computing Systems (CHI)}}

@ARTICLE{InsigHTable2024tvcg,
  author={Li, Guozheng and He, Peng and Wang, Xinyu and Li, Runfei and Liu, Chi Harold and Ou, Chuangxin and He, Dong and Wang, Guoren},
  journal=journal_tvcg, 
  abstract = {Embedding visual representations within original hierarchical tables can mitigate additional cognitive load stemming from the division of users' attention. The created hierarchical table visualizations can help users understand and explore complex data with multi-level attributes. However, because of many options available for transforming hierarchical tables and selecting subsets for embedding, the design space of hierarchical table visualizations becomes vast, and the construction process turns out to be tedious, hindering users from constructing hierarchical table visualizations with many data insights efficiently. We propose InsigHTable, a mixed-initiative and insight-driven hierarchical table transformation and visualization system. We first define data insights within hierarchical tables, which consider the hierarchical structure in the table headers. Since hierarchical table visualization construction is a sequential decision-making process, InsigHTable integrates a deep reinforcement learning framework incorporating an auxiliary rewards mechanism. This mechanism addresses the challenge of sparse rewards in constructing hierarchical table visualizations. Within the deep reinforcement learning framework, the agent continuously optimizes its decision-making process to create hierarchical table visualizations to uncover more insights by collaborating with analysts. We demonstrate the usability and effectiveness of InsigHTable through two case studies and sets of experiments. The results validate the effectiveness of the deep reinforcement learning framework and show that InsigHTable can facilitate users to construct hierarchical table visualizations and understand underlying data insights.},
  title={InsigHTable: Insight-driven Hierarchical Table Visualization with Reinforcement Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-18},
  selected={true},
  preview={insightable-preview.png},
  keywords={Data visualization;Reinforcement learning;Visualization;Asia;Decision making;Data mining;Europe;Hierarchical tabular data;table visualization;reinforcement learning;data transformation},
  doi={10.1109/TVCG.2024.3404454}}

@article{hinavimec2025jov,
  author = {Zhou, Yu and Li, Guozheng and Ding, Ding and Liu, Ye and Wang, Zhongkai and Zhang, Weijiao and Liu, Harold Chi},
  journal=journal_jov, 
  title = {HiNaviMec: Hierarchical Navigation of 3D Mechanical Models in Virtual Environments},
  abstract = {As remote maintenance becomes increasingly prevalent across various industries, the ability to remotely inspect equipment and guide on-site operations has emerged as a crucial aspect. Remote maintenance relies heavily on 3D models comprising densely packed and interconnected parts, presenting a significant challenge in navigation and comprehension for experts. We introduce HiNaviMec, a novel technique designed to enhance the understanding and navigation of complex 3D mechanical models in a virtual environment. HiNaviMec employs a connection detection algorithm for 3D models to establish connections between mechanical parts and generate the mechanical structure graph, and further utilize a weighted graph partitioning algorithm to realize the division of the overall mechanical structure. For each mechanical part, we determine the relational distance and disassembly direction based on the mechanical structure graph. Furthermore, HiNaviMec generates a hierarchical structure to facilitate the understanding of mechanical structure. The usability study on HiNaviMec demonstrates that HiNaviMec effectively aids users in comprehending the internal structure of machinery and assists experts in grasping intricate relationships between components.},
  year={2025},
  volume={},
  number={},
  pages={},
  preview={hinavimec-preview.png},
  selected={true}}

@inproceedings{BiaSeer2025cscw,
  author = {Li, Guozheng and Han, Shiyu and Wu, Jihe and Hu, Jiale and Liu, Harold Chi},
  title = {BiaSeer: A Visual Analytics System for Identifying and Understanding Media Bias},
  abstract = {Media bias refers to bias in news reporting and coverage that exists pervasively. By identifying media bias, social scientists can understand the different perspectives held by media outlets in news reporting. Existing studies only focus on the analysis of media bias of isolated incidents, but neglect their sustained characteristics. Thus, they cannot provide a comprehensive understanding of specific news topics. We develop BiaSeer, a visual analytics system for identifying and understanding sustained bias of media outlets. BiaSeer employs an overview-to-detail approach for interactive identification of media bias. The overview assists users in determining the analysis scope of media outlets. In addition, it visualizes the variances in coverage patterns between selected media outlets using a matrix visualization to facilitate the identification of biased news articles. BiaSeer visualizes the sustained bias in the context of the events evolution. It first summarizes news articles into events based on a keyword co-occurrence graph and then connects events into a narrative structure using a path-aware story tree construction method. In addition, BiaSeer integrates a sustained bias computation algorithm and enables analysts to compare the narrative structures of different media outlets using the juxtaposition-based visualization approach. We conducted a user experiment to validate the effectiveness of BiaSeer in helping social scientists understand news topics and the usability of visualization designs. To examine the effectiveness of BiaSeer, we conducted a case study with social scientists on the topics of the Russia-Ukraine conflict. The results demonstrate the utility and usability of BiaSeer in efficiently analyzing media bias and attaining a well-rounded understanding of news topics.},
  booktitle    = {Proc. ACM Hum.-Comput. Interact.},
  pages        = {1--13},
  publisher    = {{ACM}},
  year         = {2025},
  doi          = {https://doi.org/10.1145/3710936},
  timestamp    = {10 May 2025},
  biburl       = {},
  html         = {https://github.com/bitvis2021/BiaSeer},
  preview      = {biaseer-preview.png},
  pdf          = {},
  selected     = {true}}

@ARTICLE{hiregex2025li,
  author={Li, Guozheng and Mi, Haotian and Liu, Chi Harold and Itoh, Takayuki and Wang, Guoren},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={HiRegEx: Interactive Visual Query and Exploration of Multivariate Hierarchical Data}, 
  year={2025},
  volume={31},
  number={1},
  abstract = {When using exploratory visual analysis to examine multivariate hierarchical data, users often need to query data to narrow down the scope of analysis. However, formulating effective query expressions remains a challenge for multivariate hierarchical data, particularly when datasets become very large. To address this issue, we develop a declarative grammar, HiRegEx (Hierarchical data Regular Expression), for querying and exploring multivariate hierarchical data. Rooted in the extended multi-level task topology framework for tree visualizations (e-MLTT), HiRegEx delineates three query targets (node, path, and subtree) and two aspects for querying these targets (features and positions), and uses operators developed based on classical regular expressions for query construction. Based on the HiRegEx grammar, we develop an exploratory framework for querying and exploring multivariate hierarchical data and integrate it into the TreeQueryER prototype system. The exploratory framework includes three major components: top-down pattern specification, bottom-up data-driven inquiry, and context-creation data overview. We validate the expressiveness of HiRegEx with the tasks from the e-MLTT framework and showcase the utility and effectiveness of TreeQueryER system through a case study involving expert users in the analysis of a citation tree dataset.},
  pages={699-709},
  keywords={Visualization;Time series analysis;Grammar;Database languages;Data visualization;Syntactics;Topology;Multivariate hierarchical data;declarative grammar;visual query},
  doi={10.1109/TVCG.2024.3456389}}

@ARTICLE{energy2024zhao,
  author={Zhao, Yinuo and Liu, Chi Harold and Yi, Tianjiao and Li, Guozheng and Wu, Dapeng},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical Multi-Agent Deep Reinforcement Learning With Diffusion Models}, 
  year={2024},
  volume={42},
  number={12},
  pages={3566-3580},
  preview = {energy-preview.png},
  abstract = {},
  doi={10.1109/JSAC.2024.3459039}}


@inproceedings{BiaSeer2025cscw,
  author       = {Li, Guozheng and Han, Shiyu and Wu, Jihe and Hu, Jiale and Liu, Harold Chi},
  title        = {BiaSeer: A Visual Analytics System for Identifying and Understanding Media Bias},
  abstract     = {},
  booktitle    = {Proc. ACM Hum.-Comput. Interact.},
  pages        = {1--13},
  publisher    = {{ACM}},
  year         = {2025},
  doi          = {https://doi.org/10.1145/3710936},
  timestamp    = {10 May 2025},
  biburl       = {},
  html         = {https://github.com/bitvis2021/BiaSeer},
  preview      = {biaseer-preview.png},
  pdf          = {},
  selected     = {true}}
  
@article{CoInsight2023tvcg,
  author={Li, Guozheng and Li, Runfei and Feng, Yunshan and Zhang, Yu and Luo, Yuyu and Liu, Harold Chi and Wang, Guoren},
  journal=journal_tvcg, 
  title={CoInsight: Visual Storytelling for Hierarchical Tables with Connected Insights}, 
  year={2023},
  volume={},
  number={},
  pages={},
  preview={coinsight-preview.png},
  selected={true}}

@article{StickyLinks2023tvcg,
  author={Lu, Min and Zeng, Xiangfang and Lanir, Joel and Sun, Xiaoqin and Li, Guozheng and Cohen, Or Daniel and Huang, Hui},
  journal=journal_tvcg, 
  title={Sticky Links: Encoding Quantitative Data of Graph Edges}, 
  year={2023},
  volume={},
  number={},
  pages={}}

@article{HiTailor2023tvcg,
  author={Li, Guozheng and Li, Runfei and Wang, Zicheng and Liu, Chi Harold and Lu, Min and Wang, Guoren},
  journal=journal_tvcg, 
  title={HiTailor: Interactive Transformation and Visualization for Hierarchical Tabular Data}, 
  abstract={Tabular visualization techniques integrate visual representations with tabular data to avoid additional cognitive load caused by splitting users’ attention. However, most of the existing studies focus on simple flat tables instead of hierarchical tables, whose complex structure limits the expressiveness of visualization results and affects users’ efficiency in visualization construction. We present HiTailor, a technique for presenting and exploring hierarchical tables. HiTailor constructs an abstract model, which defines row/column headings as biclustering and hierarchical structures. Based on our abstract model, we identify three pairs of operators, Swap/Transpose, ToStacked/ToLinear, Fold/Unfold, for transformations of hierarchical tables to support users’ comprehensive explorations. After transformation, users can specify a cell or block of interest in hierarchical tables as a TableUnit for visualization, and HiTailor recommends other related TableUnits according to the abstract model using different mechanisms. We demonstrate the usability of the HiTailor system through a comparative study and a case study with domain experts, showing that HiTailor can present and explore hierarchical tables from different viewpoints. HiTailor is available at https://github.com/bitvis2021/HiTailor.},
  year={2023},
  volume={29},
  number={1},
  pages={139-148},
  doi={10.1109/TVCG.2022.3209354},
  pdf={2023-HiTailor-TVCG.pdf},
  preview={hitailor-preview.png},
  html={https://github.com/bitvis2021/HiTailor},
  selected={true}
}

@article{LitVis2023jov,
  author       = {Min Tian and Guozheng Li and Xiaoru Yuan},
  title        = {LitVis: a visual analytics approach for managing and exploring literature},
  journal      = journal_jov,
  abstract={Reading literature is essential to research. However, the explosive growth, the multidimensional attributes, and the complex relationships pose a tremendous challenge for researchers to understand and analyze literature efficiently. We propose LitVis, a visual analysis approach to help users manage and explore literature based on its metadata. LitVis allows users to select literature collection of interest and analyze them from their attributes, text, and citation networks. From the perspective of attribute values, LitVis supports users in understanding the distribution of literature and filtering individuals of interest. From the perspective of the text, LitVis uses the Latent Dirichlet Allocation model to extract topics from the literature and allows users to adjust the topic extraction results interactively. From the citation network perspective, LitVis enables users to analyze citation relationships within and between topics to help them understand research development. One use case and carefully designed interviews with domain experts validate the effectiveness of LitVis in the management and analysis of the literature. The results show that LitVis help users comprehensively identify the literature collection of interest and efficiently analyze the evolution of research topics.},
  volume       = {26},
  number       = {6},
  pages        = {1445--1458},
  year         = {2023},
  url          = {https://doi.org/10.1007/s12650-023-00941-3},
  doi          = {10.1007/S12650-023-00941-3},
  pdf          = {2023-LitVis-JoV.pdf},
  preview      = {litvis-preview.png},
  timestamp    = {Fri, 27 Oct 2023 20:39:48 +0200},
  biburl       = {https://dblp.org/rec/journals/jvis/TianLY23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{GoTreeScape2023tvcg,
  author={Li, Guozheng and Yuan, Xiaoru},
  journal=journal_tvcg, 
  title={GoTreeScape: Navigate and Explore the Tree Visualization Design Space}, 
  abstract={Declarative grammar has becoming an increasingly significant technique for understanding visualization design space. We propose GoTreeScape system to facilitate the navigation and exploration of the vast design space implied by GoTree, a declarative grammar of tree visualizations. To provide users with the design space overview, GoTreeScape utilizes an Encoder-Decoder architecture to project tree visualizations into a 2D landscape, taking into account the relationships between different design features. Furthermore, GoTreeScape includes an exploratory framework, enabling top-down, bottom-up, and hybrid modes to support the inherently undirected nature of exploratory search. We demonstrate that GoTreeScape can expand the diversity of user-designed tree visualizations through two case studies.},
  year={2023},
  volume={29},
  number={12},
  pages={5451-5467},
  html={https://github.com/bitvis2021/GoTreeScape},
  doi={10.1109/TVCG.2022.3215070},
  preview={gotreescape-preview.png},
  pdf={2022-GoTreeScape-TVCG.pdf},
  selected={true}
}

@article{BarcodeTree2020tvcg,
  author={Li, Guozheng and Zhang, Yu and Dong, Yu and Liang, Jie and Zhang, Jinson and Wang, Jinsong and Mcguffin, Michael J. and Yuan, Xiaoru},
  journal=journal_tvcg, 
  title={BarcodeTree: Scalable Comparison of Multiple Hierarchies}, 
  abstract={We propose BarcodeTree (BCT), a novel visualization technique for comparing topological structures and node attribute values of multiple trees. BCT can provide an overview of one hundred shallow and stable trees simultaneously, without aggregating individual nodes. Each BCT is shown within a single row using a style similar to a barcode, allowing trees to be stacked vertically with matching nodes aligned horizontally to ease comparison and maintain space efficiency. We design several visual cues and interactive techniques to help users understand the topological structure and compare trees. In an experiment comparing two variants of BCT with icicle plots, the results suggest that BCTs make it easier to visually compare trees by reducing the vertical distance between different trees. We also present two case studies involving a dataset of hundreds of trees to demonstrate BCT’s utility.},
  year={2020},
  volume={26},
  number={1},
  pages={1022-1032},
  html={https://vis.pku.edu.cn/graphvis/en/barcodetree/index.html},
  doi={10.1109/TVCG.2019.2934535},
  preview={barcodetree-preview.png},
  pdf={2019-BarcodeTree-TVCG.pdf},
  selected={true}
}

@inproceedings{GoTree2020chi,
  author       = {Guozheng Li and Min Tian and Qinmei Xu and Michael J. McGuffin and Xiaoru Yuan},
  title        = {GoTree: {A} Grammar of Tree Visualizations},
  abstract     = {We present GoTree, a declarative grammar allowing users to instantiate tree visualizations by specifying three aspects: vi- sual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both “unit-decomposable” and “axis-decomposable” (terms we define). For tree visualiza- tions within this subset, GoTree gives the user flexible and fine-grained control over the parameters of the techniques, supporting both explicit and implicit tree visualizations. We developed Tree Illustrator, an interactive authoring tool based on GoTree grammar. Tree Illustrator allows users to create a considerable number of tree visualizations, including not only existing techniques but also undiscovered and hybrid visualizations. We demonstrate the expressiveness and generative power of GoTree with a gallery of examples and conduct a qualitative study to validate the usability of Tree Illustrator.},
  booktitle    = conf_chi,
  pages        = {1--13},
  publisher    = {{ACM}},
  year         = {2020},
  url          = {https://doi.org/10.1145/3313831.3376297},
  doi          = {10.1145/3313831.3376297},
  timestamp    = {Wed, 17 May 2023 07:47:57 +0200},
  biburl       = {https://dblp.org/rec/conf/chi/0002TXMY20.bib},
  html         = {https://vis.pku.edu.cn/gotree/},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  preview      = {gotree-preview.png},
  pdf          = {2020-GoTree-CHI.pdf},
  selected     = {true}
}

@article{TokenVis2023cje,
  author={Li, Guozheng and Zhao, Cong and Chi Harold Liu and Siming Chen and Guoren Wang},
  journal={Chinese Journal of Electronics}, 
  title={TokenVis: Visual Analytics for Evolutionary Patterns of Ethereum ERC-20 Smart Contract}, 
  abstract={Blockchain techniques have received extensive attention in recent years. The cryptocurrency market based on block-chain techniques is complex and unstable, vulnerable to political, economic and social factors. Existing studies focus on native cryptocurrencies, such as Bitcoin and Ethereum. However, a large number of ERC-20 tokens in the cryptocurrency market exist. ERC-20 tokens have a great market capitalization, attracting many investors' attention. This paper proposes TokenVis, a visual analytics system to help investors understand the evolutionary patterns of different ERC-20 standard tokens and provide explanations. The TokenVis prototype system integrates a visual analytics framework with different time granularities. We propose SegRank visualization for presenting evolutionary patterns of multiple time series and a time-based COBYLA optimization algorithm to show the relationships between evolutionary patterns and news to provide explanations. We present two case studies involving the evolutionary patterns of different tokens to demonstrate the effectiveness and usability of the TokenVis prototype system.},
  year={2023},
  preview={tokenvis-preview.png},
  pdf={2023-tokenVis-cje.pdf},
}

@inproceedings{CoT2021ICSE,
  author       = {Yaohui Wang and Guozheng Li and Zijian Wang and Yu Kang and Yangfan Zhou and Hongyu Zhang and Feng Gao and Jeffrey Sun and Li Yang and Pochian Lee and Zhangwei Xu and Pu Zhao and Bo Qiao and Liqun Li and Xu Zhang and Qingwei Lin},
  title        = {Fast Outage Analysis of Large-scale Production Clouds with Service Correlation Mining},
  abstract     = {Cloud-based services are surging into popularity in recent years. However, outages, i.e., severe incidents that always impact multiple services, can dramatically affect user experience and incur severe economic losses. Locating the root- cause service, i.e., the service that contains the root cause of the outage, is a crucial step to mitigate the impact of the outage. In current industrial practice, this is generally performed in a bootstrap manner and largely depends on human efforts: the service that directly causes the outage is identified first, and the suspected root cause is traced back manually from service to service during diagnosis until the actual root cause is found. Unfortunately, production cloud systems typically contain a large number of interdependent services. Such a manual root cause analysis is often time-consuming and labor-intensive. In this work, we propose COT, the first outage triage approach that considers the global view of service correlations. COT mines the correlations among services from outage diagnosis data. After learning from historical outages, COT can infer the root cause of emerging ones accurately. We implement COT and evaluate it on a real-world dataset containing one year of data collected from Microsoft Azure, one of the representative cloud computing platforms in the world. Our experimental results show that COT can reach a triage accuracy of 82.1%∼83.5%, which outperforms the state-of-the-art triage approach by 28.0%∼29.7%.},
  booktitle    = {Proc. {IEEE/ACM} Int. Conf. Software Engineering ({ICSE})},
  pages        = {885--896},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/ICSE43902.2021.00085},
  doi          = {10.1109/ICSE43902.2021.00085},
  timestamp    = {Sat, 26 Aug 2023 22:01:09 +0200},
  pdf          = {2021-COT-ICSE.pdf},
  preview      = {cot-preview.png},
  biburl       = {https://dblp.org/rec/conf/icse/Wang0WKZZGSYLXZ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
}

@inproceedings{HiMacMic2023KDD,
  author       = {Hancheng Zhang and Guozheng Li and Chi Harold Liu and Guoren Wang and Jian Tang},
  title        = {HiMacMic: Hierarchical Multi-Agent Deep Reinforcement Learning with Dynamic Asynchronous Macro Strategy},
  abstract     = {Multi-agent deep reinforcement learning (MADRL) has been widely used in many scenarios such as robotics and game AI. However, existing methods mainly focus on the optimization of agents’ micro policies without considering the macro strategy. As a result, they cannot perform well in complex or sparse reward scenarios like the StarCraft Multi-Agent Challenge (SMAC) and Google Research Football (GRF). To this end, we propose a hierarchical MADRL framework called “HiMacMic" with dynamic asynchronous macro strategy. Spatially, HiMacMic determines a critical position by using a positional heat map. Temporally, the macro strategy dynamically decides its deadline and updates it asynchronously among agents. We validate HiMacMic in four widely used benchmarks, namely: Overcooked, GRF, SMAC and SMAC-v2 with nine chosen scenarios. Results show that HiMacMic not only converges faster and achieves higher results than ten existing approaches, but also shows its adaptability to different environment settings.},
  booktitle    = {Proc. Conf. on Knowledge Discovery and Data Mining ({KDD})},
  pages        = {3239--3248},
  publisher    = {{ACM}},
  year         = {2023},
  url          = {https://doi.org/10.1145/3580305.3599379},
  doi          = {10.1145/3580305.3599379},
  timestamp    = {Mon, 25 Sep 2023 08:29:22 +0200},
  pdf          = {2023-HiMacMic-KDD.pdf},
  preview      = {HiMacMic-preview.png},
  biburl       = {https://dblp.org/rec/conf/kdd/Zhang0LW023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Meta2023TKDE,
  author={Li, Ximing and Ma, Chen and Li, Guozheng and Xu, Peng and Liu, Chi Harold and Yuan, Ye and Wang, Guoren},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Meta Auxiliary Learning for Top-K Recommendation}, 
  abstract={Recommender systems are playing a significant role in modern society to alleviate the information/choice overload problem, since Internet users may feel hard to identify the most favorite items or products from millions of candidates. Thanks to the recent successes in computer vision, auxiliary learning has become a powerful means to improve the performance of a target (primary) task. Even though helpful, the auxiliary learning scheme is still less explored in recommendation models. To integrate the auxiliary learning scheme, we propose a novel meta auxiliary learning framework to facilitate the recommendation model training, i.e., user and item latent representations. Specifically, we construct two self-supervised learning tasks, regarding both users and items, as auxiliary tasks to enhance the representation effectiveness of users and items. Then the auxiliary and primary tasks are further modeled as a meta learning paradigm to adaptively control the contribution of auxiliary tasks for improving the primary recommendation task. This is achieved by an implicit gradient method guaranteeing less time complexity comparing with conventional meta learning methods. Via a comparison using four real-world datasets with a number of state-of-the-art methods, we show that the proposed model outperforms the best existing models on the Top-K recommendation by 3% to 23%.},
  year={2023},
  volume={35},
  number={10},
  pdf={2022-MetaAuxiliaryLearning-TKDE.pdf},
  preview={meta-preview.png},
  pages={10857-10870},
  doi={10.1109/TKDE.2022.3223155}
}

@inproceedings{UGVUAV2023ICDE,
  author       = {Wang, Yu and Wu, Jingfei and Hua, Xinyuan and Liu, Harold Chi and Li, Guozheng and Zhao, Jianxin and Yuan, Ye and Wang, Guoren},
  title        = {Air-Ground Spatial Crowdsourcing with UAV Carriers by Geometric Graph Convolutional Multi-Agent Deep Reinforcement Learning},
  abstract     = {Spatial Crowdsourcing (SC) has been proved as an effective paradigm for data acquisition in urban environments. Apart from using human participant, with the rapid development of unmanned vehicles (UVs) technologies, unmanned aerial or ground vehicles (UAVs, UGVs) are equipped with various high- precision sensors, enabling them to become new types of data collectors. However, UGVs’ operational range is constrained by the road network, and UAVs are limited by power supply, it is thus natural to use UGVs and UAVs together as a coalition, and more precisely, UGVs behave as the UAV carriers for range extensions to achieve complicated air-ground SC tasks. In this paper, we propose a novel communication-based multi- agent deep reinforcement learning method called “GARL”, which consists of a multi-center attention-based graph convolutional network (GCN) to accurately extract UGV specific features from UGV stop network called “MC-GCN”, and a novel GNN- based communication mechanism called “E-Comm” to make the cooperation among UGVs adaptive to constant changing of geometric shapes formed by UGVs. Extensive simulation results on two campuses of KAIST and UCLA campuses show that GARL consistently outperforms eight other baselines in terms of overall efficiency.},
  booktitle    = {Proc. Conf. on Int. Conf. on Data Engineering ({ICDE})},
  pages        = {1790--1802},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1145/3580305.3599379},
  doi          = {10.1145/3580305.3599379},
  timestamp    = {Mon, 25 Sep 2023 08:29:22 +0200},
  pdf          = {2023-UGVUAV-ICDE.pdf},
  preview      = {uavugv-preview.png},
  biburl       = {https://dblp.org/rec/conf/kdd/Zhang0LW023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Interaction2017pvis,
  author={Min Lu and Jie Liang and Yu Zhang and Guozheng Li and Siming Chen and Zongru Li and Yuan, Xiaoru},
  booktitle={Proc. IEEE Pacific Visualization Symposium (PacificVis)}, 
  title={Interaction+: Interaction enhancement for web-based visualizations}, 
  abstract={In this work, we present Interaction+, a tool that enhances the in- teractive capability of existing web-based visualizations. Different from the toolkits for authoring interactions during the visualization construction, Interaction+ takes existing visualizations as input, analyzes the visual objects, and provides users with a suite of interac- tions to facilitate the visual exploration, including selection, aggregation, arrangement, comparison, filtering, and annotation. Without accessing the underlying data or process how the visualization is constructed, Interaction+ is application-independent and can be employed in various visualizations on the web. We demonstrate its usage in two scenarios and evaluate its effectiveness with a qualitative user study.},
  year={2017},
  volume={},
  number={},
  pages={61-70},
  pdf={2017-Interaction+-pvis.pdf},
  preview={interaction-preview.png},
  doi={10.1109/PACIFICVIS.2017.8031580}
}

@inproceedings{Assigning2020pvisn,
  author={Han, Yun and Wang, Zhenhuang and Chen, Siming and Li, Guozheng and Zhang, Xiaolong and Yuan, Xiaoru},
  booktitle={Proc. IEEE Pacific Visualization Symposium (PacificVis, Notes)}, 
  title={Interactive Assigning of Conference Sessions with Visualization and Topic Modeling}, 
  abstract={Creating thematic sessions based on accepted papers is important to the success of a conference. Facing a large number of papers from multiple topics, conference organizers need to identify the topics of papers and group them into sessions by considering the constraints on session numbers and paper numbers in individual sessions. In this paper, we present a system using visualization and topic modeling to help the construction of conference sessions. The system provides multiple automatically generated session schemes and allows users to create, evaluate, and manipulate paper sessions with given constraints. A case study based on our system on the VAST papers shows that our method can help users successfully construct coherent conference sessions. In addition to conference session management, our method can be extended to other tasks, such as event and class schedule.},
  year={2020},
  volume={},
  number={},
  pages={236-240},
  pdf={2020-InteractiveAssignment-pvis.pdf},
  preview={assigning-preview.png},
  doi={10.1109/PacificVis48177.2020.1027x}
}

@inproceedings{TreeIllustrator2020chiea,
  author       = {Guozheng Li and Min Tian and Qinmei Xu and Michael J. McGuffin and Xiaoru Yuan},
  title        = {Tree Illustrator: Interactive Construction of Tree Visualizations},
  abstract={Creating thematic sessions based on accepted papers is important to the success of a conference. Facing a large number of papers from multiple topics, conference organizers need to identify the topics of papers and group them into sessions by considering the constraints on session numbers and paper numbers in individual sessions. In this paper, we present a system using visualization and topic modeling to help the construction of conference sessions. The system provides multiple automatically generated session schemes and allows users to create, evaluate, and manipulate paper sessions with given constraints. A case study based on our system on the VAST papers shows that our method can help users successfully construct coherent conference sessions. In addition to conference session management, our method can be extended to other tasks, such as event and class schedule.},
  booktitle    = {Extended Abstacts of ACM Conf. Human Factors in Computing Systems},
  pages        = {1--4},
  publisher    = {{ACM}},
  year         = {2020},
  url          = {https://doi.org/10.1145/3334480.3383150},
  doi          = {10.1145/3334480.3383150},
  timestamp    = {Wed, 17 May 2023 07:48:02 +0200},
  pdf          = {2020-TreeIllustrator-CHIEA.pdf},
  preview      = {illustrator-preview.png},
  biburl       = {https://dblp.org/rec/conf/chi/0002TXMY20a.bib}
}
